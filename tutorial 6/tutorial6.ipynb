{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b61d74",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{~\\middle\\vert~}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba3e65",
   "metadata": {},
   "source": [
    "# Tutorial 6: Permutation Invariance and Rotation Equivariance/Invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69ef0d",
   "metadata": {},
   "source": [
    "## 1. What does permutation invariance mean ?\n",
    "### Permutations:\n",
    "<center><img src=\"figures/balls.png\" width=\"100\" /></center>\n",
    "Each of the six rows is a different permutation of three distinct balls.\n",
    "\n",
    "__In more mathematical terms__:<br>\n",
    "Since permutations are bijections of a set, they can be represented by Cauchy's two-line notation. This notation lists each of the elements of M in the first row, and for each element, its image under the permutation below it in the second row. If $\\sigma$ is a permutation of the set $M=\\{x_1,... x_n\\}$ then:\n",
    "<center><img src=\"figures/group_theory_permutation.png\" width=\"500\" /></center>\n",
    "\n",
    "For instance, a particular permutation of the set {1, 2, 3, 4, 5} can be written as:\n",
    "<center><img src=\"figures/permutation_example.png\" width=\"300\" /></center>\n",
    "\n",
    "This means that σ satisfies σ(1) = 2, σ(2) = 5, σ(3) = 4, σ(4) = 3, and σ(5) = 1. The elements of M need not appear in any special order in the first row, so the same permutation could also be written as:\n",
    "<center><img src=\"figures/permutation_example2.png\" width=\"300\" /></center>\n",
    "\n",
    "The permutation matrix $P_\\pi$ corresponding to the permutation $\\sigma$:\n",
    "<center><img src=\"figures/permutation_example3.png\" width=\"300\" /></center>\n",
    "\n",
    "is:\n",
    "<center><img src=\"figures/permutation_matrix.png\" width=\"300\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3d167",
   "metadata": {},
   "source": [
    "### Invariance:\n",
    "An invariant is a property of a mathematical object which remains unchanged after operations or transformations of a certain type are applied to the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a05b7",
   "metadata": {},
   "source": [
    "### Permutation Invariance in a nutshell:\n",
    "$y=f(X)=f(P\\cdot X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1587418f",
   "metadata": {},
   "source": [
    "## 1.1 Permutation invariance is rather easy for GNNs!\n",
    "A typical graph neural network would apply an activation function (or several layers of neural network) to each of the adjacent node, then take the sum of the outputs, and add it to the features of the node, optionally applying another transformation function.\n",
    "\n",
    "A reminder, in Graph Convolutional Networks, the element-wise mean pooling is used instead, and the AGGREGATE and COMBINE steps are integrated as follows:\n",
    "<center><img src=\"figures/gcn_eq.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1e0a3",
   "metadata": {},
   "source": [
    "## 1.2 PointNet - An advanced permutation invariance architecture\n",
    "The design of a deep learning framework that directly consumes unordered point sets as inputs. A point cloud is represented as a set of 3D points $\\{P_i | i = 1, ..., n\\}$, where each point $P_i$ is a vector of its (x, y, z) coordinate plus extra feature channels such as color, normal etc. For simplicity and clarity, unless otherwise noted, we only use the (x, y, z) coordinate as our point’s channels.\n",
    "\n",
    "The idea is to approximate a general function defined on a point set by applying a symmetric function on transformed elements in the set:\n",
    "\n",
    "$f({x_1,...,x_n}) ≈ g(h(x_1),...,h(x_n))$\n",
    "\n",
    "where $f: 2^\\left(R^N\\right) → R$, $h: R^N → R^K$ and $g:R^K ×···× R^K → R$ is a symmetric function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9f067",
   "metadata": {},
   "source": [
    "Empirically, this basic module is very simple: we approximate h by a multi-layer perceptron network and g by a composition of a single variable function and a max pooling function. This is found to work well by experiments. Through a collection of h, we can learn a number of f ’s to capture different properties of the set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55eb7f",
   "metadata": {},
   "source": [
    "A scary image of the PointNet architecture:\n",
    "<center><img src=\"figures/pointnet-architecture.png\" width=\"700\" /></center>\n",
    "\n",
    "Additional horrific images can be found at \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\": https://arxiv.org/pdf/1612.00593.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72aeda5",
   "metadata": {},
   "source": [
    "## 2. What does rotation equivariance/invariance mean ?\n",
    "### 2.1. Group Theory\n",
    "You can watch a short fun primer video on group theory from 3Blue1Brown.\n",
    "\n",
    "A group is a general object in mathematics. A group is a set of elements that can be combined in a binary operation whose output is another member of the group. The most common example are the integers. If you combine two integers in a binary operation, the output is another integer. Of course, it depends on the operation (1 ÷ 2 does not give an integer), so specifically consider addition. Integers are not the example we care about though. We’re interested in groups of transformations that move points in a space. Operations like rotation, scaling, mirroring, or translating of single points. As you read about groups here, remember that the elements of the groups are not numbers or points. The group elements are transformations that act on points in the space. Notice I’m being a bit nebulous on what the space is for now. Let’s first define a group:\n",
    "<center><img src=\"figures/group_definition.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3626cb0",
   "metadata": {},
   "source": [
    "This is quite a bit of nice structure. We always have an inverse available. Applying the binary operations never accidentally leaves our group. One important property that is missing from this list is commutativity. In general, a group is not commutative so that a⋅b≠b⋅a. If the group does have this extra property, we call the group abelian. Another detail is how big the set is. It can indeed be infinite, which is why the integers or all possible rotations of a sphere can be represented as a group. One notational convenience we’ll make is that the binary operation “⋅” will just be referred to as multiplication. The number of elements in a group |G| is known as the order.\n",
    "\n",
    "The point of introducing the groups is so that they can transforms elements of our space. This is done through a group action:\n",
    "<center><img src=\"figures/group_action.png\" width=\"700\" /></center>\n",
    "<center><img src=\"figures/group_action_details.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed86920",
   "metadata": {},
   "source": [
    "### 2.2 SO(3) Lie Group\n",
    "\n",
    "SO(3) is the group for analyzing 3D point clouds like trajectories or crystal structures (with no other symmetries). SO(3) is the group of all rotations about the origin in 3D. The group is non-abelian because rotations in 3D are not commutative. The group order is infinite, because you can rotate in this group by any angle (or sets of angles). If you are interested in allowing translations, you can use SE(3) which is the semidirect product of SO(3) and the translation group (like p4m), which is a normal subgroup.\n",
    "\n",
    "The SO(3) name is a bit strange. SO stands for “special orthogonal” which are two properties of square matrices. In this case, the matrices are 3×3. Orthogonal means the columns sum to one and special means the determinant is 1. Interestingly, all rotations in 3D around the origin are also the SO(3) matrices.\n",
    "\n",
    "One detail is that since we’re rotating (no scale or translation) our points will all be on a sphere. We cannot move the radius. By convention then we’ll have a radius 1. The group action is the product of 3 3D rotation matrices:\n",
    "<center><img src=\"figures/rotation_matrices.png\" width=\"300\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b05a70",
   "metadata": {},
   "source": [
    "### 2.3 Equivariance\n",
    "Equivariance can be formalized using the concept of a G-set for a group G. This is a mathematical object consisting of a mathematical set S and a group action (on the left) of G on S. If X and Y are both G-sets for the same group G, then a function f : X → Y is said to be equivariant if <br> f(g·x) = g·f(x) for all g ∈ G and all x in X.\n",
    "\n",
    "The equivariance condition can also be understood as the following commutative diagram. Note that g⋅ denotes the map that takes an element z and returns g⋅z.\n",
    "<center><img src=\"figures/Equivariant_commutative_diagram.png\" width=\"300\" /></center>\n",
    "\n",
    "This is very reminiscing of isomorphism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd8f19",
   "metadata": {},
   "source": [
    "### 2.3 How are rotation equivairant and permutation invariant models built?\n",
    "Rotation equivariant models are composed of 3 parts a head, a body and a tail.\n",
    "\n",
    "__The head__ is a rotation equivariant network which takes in the data/input.<br>\n",
    "f(g·x) = g·f(x) for all g ∈ G and all x in X. <br>\n",
    "An example of such a block would be a __single GCN layer__.\n",
    "\n",
    "__The body__ is a rotation invariant network which takes in the output on the head.<br>\n",
    "f(g·x) = f(x) for all g ∈ G and all x in X.<br>\n",
    "An example of such a block would be a __2-norm__.\n",
    "\n",
    "__The tail__ is an MLP which takes in the output on the body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4652d9f6",
   "metadata": {},
   "source": [
    "### 2.4 SE(3)-Transformer - An advanced rotation equivariant and permutation invariance architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd7534",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/SE(3)-Transformer.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8989a75",
   "metadata": {},
   "source": [
    "These are the construction of a graph from a point cloud, the construction of equivariant edge functions on the graph, how to propagate SE(3)-equivariant messages on the graph, and how to aggregate them.\n",
    "\n",
    "__Step 1:__<br>\n",
    "Given a pointcloud $\\{(x_i,f_i)\\}$,we first introduce acollection of neighbourhoods $N_i ⊆\\{1,...,N\\}$, one centered on each point i. These neighbourhoods are computed either via the nearest-neighbours methods or may already be defined. For instance, molecular structures have neighbourhoods defined by their bonding structure. Neighbourhoods reduce the computational complexity of the attention mechanism from quadratic in the number of points to linear. The introduction of neighbourhoods converts our point cloud into a graph.\n",
    "\n",
    "__Step 2:__<br>\n",
    "Using a block called a \"Tensor Field Network\". Additional details can be found at \"Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds\": https://arxiv.org/abs/1802.08219  \n",
    "\n",
    "__Step 3-4:__ Completing the attention calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139c899",
   "metadata": {},
   "source": [
    "__Note:__<br>\n",
    "The SE(3)-Transformer itself consists of three components. These are\n",
    "1) Edge-wise attention weights $α_{ij}$ , constructed to be SE(3)-invariant on each edge ij <br>\n",
    "2) Edge-wise SE(3)-equivariant value messages, propagating information between nodes, as found in the TFN convolution<br>\n",
    "3) A linear/attentive self-interaction layer.<br>\n",
    "\n",
    "Attention is performed on a per-neighbourhood basis as follows:\n",
    "<center><img src=\"figures/se3_equation.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fcfcc1",
   "metadata": {},
   "source": [
    "<center><img src=\"figures/thank_you.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd3638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geometric_tutorial",
   "language": "python",
   "name": "pytorch_geometric_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
