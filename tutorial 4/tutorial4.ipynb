{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8603a0ea",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{~\\middle\\vert~}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca29bcf",
   "metadata": {},
   "source": [
    "# Tutorial 4: The GAT architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a112e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install pytorch-lightning==1.3.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"./saved_models\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba8222",
   "metadata": {},
   "source": [
    "We also have a few pre-trained models we download below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee29245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(\"Downloading %s...\" % file_url)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186beab5",
   "metadata": {},
   "source": [
    "### 1. Reminder - Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49ebfc",
   "metadata": {},
   "source": [
    "The attention mechanism describes a recent new group of layers in neural networks that has attracted a lot of interest in the past few years, especially in sequence tasks. There are a lot of different possible definitions of “attention” in the literature, but the one we will use here is the following: __the attention mechanism describes a weighted average of (sequence) elements with the weights dynamically computed based on an input query and elements’ keys.__ So what does this exactly mean? The goal is to take an average over the features of multiple elements. However, instead of weighting each element equally, we want to weight them depending on their actual values. In other words, we want to dynamically decide on which inputs we want to “attend” more than others. In particular, an attention mechanism has usually four parts we need to specify:\n",
    "\n",
    "- Query: The query is a feature vector that describes what we are looking for in the sequence, i.e. what would we maybe want to pay attention to.\n",
    "- Keys: For each input element, we have a key which is again a feature vector. This feature vector roughly describes what the element is “offering”, or when it might be important. The keys should be designed such that we can identify the elements we want to pay attention to based on the query.\n",
    "- Values: For each input element, we also have a value vector. This feature vector is the one we want to average over.\n",
    "- Score function: To rate which elements we want to pay attention to, we need to specify a score function $f_{attn}$. The score function takes the query and a key as input, and output the score/attention weight of the query-key pair. It is usually implemented by simple similarity metrics like a dot product, or a small MLP.\n",
    "\n",
    "The weights of the average are calculated by a softmax over all score function outputs. Hence, __we assign those value vectors a higher weight whose corresponding key is most similar to the query.__ If we try to describe it with pseudo-math, we can write:\n",
    "\n",
    "$\\alpha_i = \\frac{\\exp\\left(f_{attn}\\left(\\text{key}_i, \\text{query}\\right)\\right)}{\\sum_j \\exp\\left(f_{attn}\\left(\\text{key}_j, \\text{query}\\right)\\right)}, \\hspace{5mm} \\text{out} = \\sum_i \\alpha_i \\cdot \\text{value}_i$\n",
    "\n",
    "Visually, we can show the attention over a sequence of words as follows:\n",
    "\n",
    "<center><img src=\"figures/attention_example.svg\" width=\"700\" /></center>\n",
    "\n",
    "For every word, we have one key and one value vector. The query is compared to all keys with a score function (in this case the dot product) to determine the weights. The softmax is not visualized for simplicity. Finally, the value vectors of all words are averaged using the attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d2336",
   "metadata": {},
   "source": [
    "2. The Graph Attention Network (GAT) Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5ed3c",
   "metadata": {},
   "source": [
    "This concept can be similarly applied to graphs, one of such is the Graph Attention Network (called GAT, proposed by [Velickovic et al., 2017](https://arxiv.org/abs/1710.10903)). Similarly to the GCN, the graph attention layer creates a message for each node using a linear layer/weight matrix.\n",
    "\n",
    "For the attention part, __it uses the message from the node itself as a query, and the messages to average as both keys and values__ (note that this also includes the message to itself). The score function $f_{attn}$ is implemented as a one-layer MLP which maps the query and key to a single value. The MLP looks as follows (figure credit - [Velickovic et al.](https://arxiv.org/abs/1710.10903)):\n",
    "\n",
    "<center width=\"100%\" style=\"padding:10px\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial7/graph_attention_MLP.svg?raw=1\" width=\"250px\"></center>\n",
    "\n",
    "$h_i$ and $h_j$ are the original features from node $i$ and $j$ respectively, and represent the messages of the layer with $\\mathbf{W}$ as weight matrix. $\\mathbf{a}$ is the weight matrix of the MLP, which has the shape $[1,2\\times d_{\\text{message}}]$, and $\\alpha_{ij}$ the final attention weight from node $i$ to $j$. The calculation can be described as follows:\n",
    "\n",
    "$$\\alpha_{ij} = \\frac{\\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_j\\right]\\right)\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_k\\right]\\right)\\right)}$$\n",
    "\n",
    "The operator $||$ represents the concatenation, and $\\mathcal{N}_i$ the indices of the neighbors of node $i$. __Note that in contrast to usual practice, we apply a non-linearity (here LeakyReLU) before the softmax over elements.__ Although it seems like a minor change at first, it is crucial for the attention to depend on the original input. \n",
    "\n",
    "Specifically, let's remove the non-linearity for a second, and try to simplify the expression:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\alpha_{ij} & = \\frac{\\exp\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_j\\right]\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}\\left[\\mathbf{W}h_i||\\mathbf{W}h_k\\right]\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i+\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i+\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i\\right)\\cdot\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,:d/2}\\mathbf{W}h_i\\right)\\cdot\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\[5pt]\n",
    "    & = \\frac{\\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_j\\right)}{\\sum_{k\\in\\mathcal{N}_i} \\exp\\left(\\mathbf{a}_{:,d/2:}\\mathbf{W}h_k\\right)}\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We can see that without the non-linearity, the attention term with $h_i$ actually cancels itself out, resulting in the attention being independent of the node itself. Hence, __we would have the same issue as the GCN of creating the same output features for nodes with the same neighbors.__ This is why the LeakyReLU is crucial and adds some dependency on $h_i$ to the attention. \n",
    "\n",
    "Once we obtain all attention factors, we can calculate the output features for each node by performing the weighted average:\n",
    "\n",
    "$$h_i'=\\sigma\\left(\\sum_{j\\in\\mathcal{N}_i}\\alpha_{ij}\\mathbf{W}h_j\\right)$$\n",
    "\n",
    "$\\sigma$ is yet another non-linearity, as in the GCN layer. Visually, we can represent the full message passing in an attention layer as follows (figure credit - [Velickovic et al.](https://arxiv.org/abs/1710.10903)):\n",
    "\n",
    "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial7/graph_attention.jpeg?raw=1\" width=\"400px\"></center>\n",
    "\n",
    "After having discussed the graph attention layer in detail, we can implement it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce353e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimensionality of input features\n",
    "            c_out - Dimensionality of output features\n",
    "            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The \n",
    "                        output features are equally split up over the heads if concat_heads=True.\n",
    "            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n",
    "            alpha - Negative slope of the LeakyReLU activation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
    "            c_out = c_out // num_heads\n",
    "        \n",
    "        # Sub-modules and parameters needed in the layer\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # One per head\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "        \n",
    "        # Initialization from the original implementation\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Input features of the node. Shape: [batch_size, c_in]\n",
    "            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
    "            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
    "        \n",
    "        # Apply linear layer and sort nodes by head\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "        \n",
    "        # We need to calculate the attention logits for every edge in the adjacency matrix \n",
    "        # Doing this on all possible combinations of nodes is very expensive\n",
    "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
    "        edges = adj_matrix.nonzero(as_tuple=False) # Returns indices where the adjacency matrix is not 0 => edges\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
    "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
    "        ], dim=-1) # Index select returns a tensor with node_feats_flat being indexed at the desired positions along dim=0\n",
    "        \n",
    "        # Calculate attention MLP output (independent for each head)\n",
    "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a) \n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "        \n",
    "        # Map list of attention values back into a matrix\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "        \n",
    "        # Weighted average of attention\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
    "        \n",
    "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "        \n",
    "        return node_feats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7da137",
   "metadata": {},
   "source": [
    "Again, we can apply the graph attention layer on our example graph above to understand the dynamics better. As before, the input layer is initialized as an identity matrix, but we set $\\mathbf{a}$ to be a vector of arbitrary numbers to obtain different attention values. We use two heads to show the parallel, independent attention mechanisms working in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b35e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19902179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention probs\n",
      " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
      "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
      "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
      "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
      "\n",
      "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
      "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
      "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
      "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
      "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n",
      "Input features tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Output features tensor([[[1.2913, 1.9800],\n",
      "         [4.2344, 3.7725],\n",
      "         [4.6798, 4.8362],\n",
      "         [4.5043, 4.7351]]])\n"
     ]
    }
   ],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd57d58",
   "metadata": {},
   "source": [
    "## 3. Generic GNN architectures - notations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad6bbc",
   "metadata": {},
   "source": [
    "We begin by summarizing some of the most common GNN models and, along the way, introduce our notation. Let $G = (V, E)$ denote a graph with node feature vectors $X_{v}$ for $v \\in V$. There are two tasks of interest:\n",
    "1. Node classification, where each node $v \\in V$ has an associated label $y_{v}$ and the goal is to learn a representation vector $h_{v}$ of v such that v’s label can be predicted as $y_v = f(h_v)$\n",
    "2. Graph classification, where, given a set of graphs $\\{G_{1} , ..., G_{N} \\} \\subset G$ and their labels $\\{y_1 , ..., y_N \\} \\subset Y$ , we aim to learn a representation vector $h_G$ that helps predict the label of an entire graph, $y_G = g(h_G)$\n",
    "\n",
    "Graph Neural Networks. GNNs use the graph structure and node features $X_{v}$ to learn a representation vector of a node, $h_v$, or the entire graph, $h_G$. Modern GNNs follow a neighborhood aggregation strategy, where we iteratively update the representation of a node by aggregating representations of its neighbors. After k iterations of aggregation, a node’s representation captures the structural information within its k-hop network neighborhood. Formally, the k-th layer of a GNN is:\n",
    "\n",
    "<center><img src=\"figures/gnn_eq.png\" /></center>\n",
    "\n",
    "\n",
    "Where $h_v^k$ is the feature vector of node v at the k-th iteration/layer. We initialize $h_v^0 = X_v$, and\n",
    "N(v) is a set of nodes adjacent to v. The choice of $AGGREGATE^k (·)$ and $COMBINE^k (·)$ in GNNs is crucial. A number of architectures for AGGREGATE have been proposed.\n",
    "\n",
    "In Graph Convolutional Networks, the element-wise mean pooling is used instead, and the AGGREGATE and COMBINE steps are integrated as follows:\n",
    "\n",
    "<center><img src=\"figures/gcn_eq.png\" width=\"700\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a00d0",
   "metadata": {},
   "source": [
    "Common examples for AGGREGATE are:\n",
    "1. Mean\n",
    "2. Weighted mean\n",
    "3. Max\n",
    "4. Summation\n",
    "\n",
    "While COMBINE can be any function of our interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759da586",
   "metadata": {},
   "source": [
    "For node classification, the node representation $h_v$ of the final iteration is used for prediction. For\n",
    "graph classification, the READOUT function aggregates node features from the final iteration to obtain the entire graph’s representation $h_G$:\n",
    "\n",
    "$h = READOUT \\left(\\{h_v^K | v \\in G\\}\\right)$\n",
    "\n",
    "READOUT can be a simple permutation invariant function such as summation or a more sophisticated graph-level pooling function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376116f",
   "metadata": {},
   "source": [
    "## 4. PyTorch Geometric installation snipplet\n",
    "\n",
    "We had mentioned before that implementing graph networks with adjacency matrix is simple and straight-forward but can be computationally expensive for large graphs. Many real-world graphs can reach over 200k nodes, for which adjacency matrix-based implementations fail. There are a lot of optimizations possible when implementing GNNs, and luckily, there exist packages that provide such layers. The most popular packages for PyTorch are [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) and the [Deep Graph Library](https://www.dgl.ai/) (the latter being actually framework agnostic). Which one to use depends on the project you are planning to do and personal taste. In this tutorial, we will look at PyTorch Geometric as part of the PyTorch family. Similar to PyTorch Lightning, PyTorch Geometric is not installed by default on GoogleColab (and actually also not in our `dl2020` environment due to many dependencies that would be unnecessary for the practicals). Hence, let's import and/or install it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b15c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch geometric\n",
    "try: \n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    # You might need to install those packages with specific CUDA+PyTorch version. \n",
    "    # The following ones below have been picked for Colab (Jun 2021).\n",
    "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details \n",
    "    !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "    !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "    !pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
    "    !pip install torch-geometric\n",
    "    import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d38da",
   "metadata": {},
   "source": [
    "PyTorch Geometric provides us a set of common graph layers, including the GCN and GAT layer we implemented above. Additionally, similar to PyTorch's torchvision, it provides the common graph datasets and transformations on those to simplify training. Compared to our implementation above, PyTorch Geometric uses a list of index pairs to represent the edges. The details of this library will be explored further in our experiments.\n",
    "\n",
    "In our tasks below, we want to allow us to pick from a multitude of graph layers. Thus, we define again below a dictionary to access those using a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d3c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a74e2e",
   "metadata": {},
   "source": [
    "Additionally to GCN and GAT, we added the layer `geom_nn.GraphConv` ([documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GraphConv)). GraphConv is a GCN with a separate weight matrix for the self-connections. Mathematically, this would be:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(l+1)} = \\mathbf{W}^{(l + 1)}_1 \\mathbf{x}_i^{(l)} + \\mathbf{W}^{(\\ell + 1)}_2 \\sum_{j \\in \\mathcal{N}_i} \\mathbf{x}_j^{(l)}\n",
    "$$\n",
    "\n",
    "__In this formula, the neighbor's messages are added instead of averaged.__ However, PyTorch Geometric provides the argument `aggr` to switch between summing, averaging, and max pooling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geometric_tutorial",
   "language": "python",
   "name": "pytorch_geometric_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
